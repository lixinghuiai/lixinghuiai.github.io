[{"title":"Leetcode_2. Add Two Numbers","date":"2017-05-14T08:42:56.000Z","path":"2017/05/14/Leetcode-2-Add-Two-Numbers/","text":"这是崔斯特的第十篇原创文章 好久没写博客了，定个小目标，2天一篇，哈哈。 1、题目You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) Output: 7 -&gt; 0 -&gt; 8 2、思路其实我并看不懂题目说得啥意思，如果说243+564，结果是807才是，但是很明显题目不会这么简单。怎么办？ 好像只能去看看别人的理解了，发现： 1.因为存储是反过来的，即数字342存成2-&gt;4-&gt;3，所以要注意进位是向后的； 2.链表l1或l2为空时，直接返回，这是边界条件，省掉多余的操作； 3.链表l1和l2长度可能不同，因此要注意处理某个链表剩余的高位； 4.2个数相加，可能会产生最高位的进位，因此要注意在完成以上1－3的操作后，判断进位是否为0，不为0则需要增加结点存储最高位的进位。 给个链接http://blog.csdn.net/zhouworld16/article/details/14045855 原来是倒着相加，342+465=807，结果倒序，正好是708，题目应该是这样理解的吧，哈哈。 思路本题的思路很简单，按照小学数学中学习的加法原理从末尾到首位，对每一位对齐相加即可。技巧在于如何处理不同长度的数字，以及进位和最高位的判断。这里对于不同长度的数字，我们通过将较短的数字补0来保证每一位都能相加。递归写法的思路比较直接，即判断该轮递归中两个ListNode是否为null。 全部为null时，返回进位值 有一个为null时，返回不为null的那个ListNode和进位相加的值 都不为null时，返回 两个ListNode和进位相加的值 来源一位大佬https://segmentfault.com/a/1190000002986101 原来是小学内容小学数学中学习的加法，使用递归写法。 递归，就是在运行的过程中调用自己。什么鬼啊，自己使用自己吗？ 目前我找到的对递归最恰当的比喻，就是查词典。 我们使用的词典，本身就是递归，为了解释一个词，需要使用更多的词。 当你查一个词，发现这个词的解释中某个词仍然不懂，于是你开始查这第二个词，可惜，第二个词里仍然有不懂的词，于是查第三个词，这样查下去，直到有一个词的解释是你完全能看懂的，那么递归走到了尽头，然后你开始后退，逐个明白之前查过的每一个词，最终，你明白了最开始那个词的意思。。。 好像明白了一点点~ 3、解法 #（Python）版本1 class Solution: def addTwoNumbers(self, l1, l2): addends = l1, l2 dummy = end = ListNode(0) carry = 0 while addends or carry: carry += sum(a.val for a in addends) addends = [a.next for a in addends if a.next] end.next = end = ListNode(carry % 10) carry /= 10 return dummy.next 版本2 class Solution: # @return a ListNode def addTwoNumbers(self, l1, l2): carry = 0 sum = ListNode(0) s = sum while l1 is not None or l2 is not None or carry: s.val = carry if l1: s.val += l1.val l1 = l1.next if l2: s.val += l2.val l2 = l2.next carry = s.val / 10 s.val = s.val % 10 if l1 or l2 or carry: s.next = ListNode(0) s = s.next return sum 好吧，承认版本1看不懂。至于版本2 ListNode 是一个元祖，然后。。。s.val是什么意思啊？又不懂。回去看看，原来是已经定义了ListNode # Definition for singly-linked list. # class ListNode(object): # def __init__(self, x): # self.val = x # self.next = None 也就是说有2个类，Solution 和 ListNode 今天先这样了，我需要去学习一下什么是“类”，也就是Python的面向对象编程","tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://zhangslob.github.io/tags/leetcode/"},{"name":"刷题","slug":"刷题","permalink":"https://zhangslob.github.io/tags/刷题/"}]},{"title":"使用Python计算文章中的字词频率丨学习笔记和反思","date":"2017-03-28T10:58:18.000Z","path":"2017/03/28/使用Python计算文章中的字词频率丨学习笔记和反思/","text":"这是崔斯特的第九篇原创文章 来源：天善智能-商业智能和大数据在线社区，用心创造价值https://edu.hellobi.com/course/159/play/lesson/2531 丘祐玮https://ask.hellobi.com/people/DavidChiu人人都爱数据科学家！Python数据科学精华实战课程 环境：Anaconda3 建议使用Anaconda，下载源文件后再阅读本文：https://github.com/zhangslob/DanmuFenxi 选择经典演讲稿，奥巴马2009年9月8日开学演讲。。https://wenku.baidu.com/view/ad77bc1caf45b307e8719758.html THE PRESIDENT: Hello, everybody! Thank you. Thank you. Thank you, everybody. All right, everybody go ahead and have a seat. How is everybody doing today? (Applause.) How about Tim Spicer? (Applause.) I am here with students at Wakefield High School in Arlington, Virginia. And we’ve got students tuning in from all across America, from kindergarten through 12th grade. And I am just so glad that all could join us today. And I want to thank Wakefield for being such an outstanding host. Give yourselves a big round of applause. (Applause.)… 1、World Count(Version 1)把数据命名为speech_text，首先需要对英文进行分词。英文中主要是空格，使用split()函数 # coding: utf-8 # In[1]: speech_text=&apos;&apos;&apos;#长文本使用&apos;&apos;&apos;..&apos;&apos;&apos; THE PRESIDENT: Hello, everybody! Thank you. Thank you. Thank you, everybody. All right, everybody go ahead and have a seat. How is everybody doing today? (Applause.) How about Tim Spicer? (Applause.) I am here with students at Wakefield High School in Arlington, Virginia. And we&apos;ve got students tuning in from all across America, from kindergarten through 12th grade. And I am just so glad that all could join us today. And I want to thank Wakefield for being such an outstanding host. Give yourselves a big round of applause. (Applause.) ...#省略文字 &apos;&apos;&apos; # In[2]: speech=speech_text.split() # In[3]: speech 下一步，计算speech中词语出现的次数 # In[4]: dic={} for word in speech: if word not in dic: dic[word] = 1 else: dic[word] = dic[word] + 1 # In[5]: dic 通过 items() 函数以列表返回可遍历的(键, 值) 元组数组。 下一步，对词语进行排序 # In[7]: import operator swd=sorted(dic.items(),key=operator.itemgetter(1),reverse=True)#从大到小排序 # In[9]: swd 发现其中“to”、“the”等单词是常见词，借用nltk我们可以把这些词语去掉 from nltk.corpus import stopwords stop_words = stopwords.words(&apos;English&apos;) 虽说Anaconda已经安装了NLTK，但是我自己操作时stopwords貌似没有，出错请参考https://www.douban.com/note/534906136/ 看看英文中的去停词，下一步，遍历，打印出不含有去停词 for k,v in swd2: if k not in stop_words: print(k,v) 发现出现了很多“–”，回去原文中观察，发现确实有很多， 那么问题来了，为什么出现这么多“–”。萌新求解！ 2、World Count(Version 2)from collections import Counter c=Counter(speech2) 使用Python 的collections模块更简洁，详细见http://www.jb51.net/article/48771.htm 同样可以使用stop_word，还可以使用most_common打印出前几个 for sw in stop_words: del c[sw] 3、反思上一篇文章https://zhuanlan.zhihu.com/p/25983014写的比较粗糙，很多人要求把“观众” “礼物”筛选出来，那我来试试。 stop = [&apos;！&apos;,&apos;*&apos;,&apos;观众&apos;,&apos;礼物&apos;,&apos;:&apos;,&apos;？&apos;,&apos;。&apos;,&apos;，&apos;,&apos;~&apos;,&apos;1&apos;] 去停词只有这些、可以根据实际情况添删。 看来观众很喜欢说“xx学院发来贺电~~”","tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"https://zhangslob.github.io/tags/学习笔记/"},{"name":"文字处理","slug":"文字处理","permalink":"https://zhangslob.github.io/tags/文字处理/"}]},{"title":"昨天看球时，球迷都说了啥——弹幕抓取与分析","date":"2017-03-24T12:41:58.000Z","path":"2017/03/24/昨天看球时，球迷都说了啥——弹幕抓取与分析/","text":"这是崔斯特的第八篇原创文章 数据来源：http://star.longzhu.com/teamchina 本次弹幕记录（开始时间: 2017-03-23-19:43:34，结束21:29:33)，共记录20788条数据。 使用OBS弹幕助手记录http://www.obsapp.com/apps/obsdanmu/ 1、分析 文件中含有时间记录，观众ID和送礼记录，其次是弹幕内容，所以决定对前两列内容不分析。 首先需要对文本分词，这里采用jieba分词 https://github.com/fxsjy/jieba/ 去除空格，使用strip()函数， 去掉换行符”\\n” line = line.strip(&apos;\\n&apos;) 把分析结果写入新的文档’text.txt’，Python join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串 text = &apos;&apos; with open(&apos;danmu.txt&apos;,encoding=&apos;utf-8&apos;) as fin: for line in fin.readlines(): line = line.strip(&apos;\\n&apos;) text += &apos;/&apos;.join(jieba.cut(line)) text += &apos; &apos; fout = open(&apos;text.txt&apos;,&apos;wb&apos;)#以二进制写模式写入 pickle.dump(text,fout) fout.close() 这样就完成了分词过程，结果如下： 2、绘制图云# 直接从文件读取数据 fr = open(&apos;text.txt&apos;,&apos;rb&apos;) text = pickle.load(fr) 使用word_cloud，具体用法https://github.com/amueller/word_cloud backgroud_Image = plt.imread(&apos;girl.jpg&apos;) wc = WordCloud( background_color = &apos;white&apos;, # 设置背景颜色 mask = backgroud_Image, # 设置背景图片 max_words = 2000, # 设置最大现实的字数 stopwords = STOPWORDS, # 设置停用词 font_path = &apos;C:/Users/Windows/fonts/msyh.ttf&apos;,# 设置字体格式，如不设置显示不了中文 max_font_size = 300, # 设置字体最大值 random_state = 50, # 设置有多少种随机生成状态，即有多少种配色方案 ) 使用matplotlib绘图http://matplotlib.org/2.0.0/index.html wc.generate(text) image_colors = ImageColorGenerator(backgroud_Image) #wc.recolor(color_func = image_colors) plt.imshow(wc) plt.axis(&apos;off&apos;) plt.show() OK，这样就完成了，附上结果 有没有你发过的弹幕呢？ 可自形修改数据，得到更好看图片。 能力有限，分析很少，如果你想进行更深入分析，请找我要文件。 对英雄联盟感兴趣的小伙伴可以看看这篇，对游戏直播弹幕的分析。 https://zhangslob.github.io/2017/03/24/%E5%88%A9%E7%94%A8Python%E5%AF%B9%E7%9B%B4%E6%92%AD%E5%BC%B9%E5%B9%95%E7%9A%84%E5%88%86%E6%9E%90/ github：https://github.com/zhangslob/DanmuFenxi","tags":[{"name":"足球","slug":"足球","permalink":"https://zhangslob.github.io/tags/足球/"},{"name":"数据分析","slug":"数据分析","permalink":"https://zhangslob.github.io/tags/数据分析/"}]},{"title":"利用Python对直播弹幕的分析","date":"2017-03-24T12:12:58.000Z","path":"2017/03/24/利用Python对直播弹幕的分析/","text":"这是崔斯特的第七篇原创文章 弹幕（ barrage），中文流行词语，原意指用大量或少量火炮提供密集炮击。而弹幕，顾名思义是指子弹多而形成的幕布， 大量吐槽评论从屏幕飘过时效果看上去像是飞行射击游戏里的弹幕。 今天就来说说游戏直播中， 弹幕都有哪些。 一、准备利用 danmu 弹幕接口对斗鱼主播赏金术士直播间的弹幕进行抓取，抓取时间约2 小时，共计 2534 条弹幕。赏金直播间： https://www.douyu.com/846805 二、 分析1、 弹幕词云词云， 由词汇组成类似云的彩色图形。 使用的是 Python 的模块 wordcloud。 通过 jieba 分词对弹幕中文分词， 使用 wordcloud 对结果构造词云， 最终结果为： 可以看到，高频率词语有： 外甥、无敌、厉害、可以、无限、火力、什么、垃圾、赏金。 2、关键词TextRank算法可以用来从文本中提取关键词和摘要 关键词： 不 0.010922664205428556 外甥 0.010484629632807344 玩 0.008177160003721682 无限 0.0058741805660283575 没 0.005665342357801469 说 0.005548941560115147 大 0.005541099430280024 主播 0.005498954448927515 出 0.0054948076800822405 看 0.0051528084835430555 可以看出来，作为汉字常用字，‘不’、‘玩’、‘没’、‘说’、‘大’、‘出’、‘看’这7个字出现频率高，这不奇怪。但是，‘外甥’、‘无限’、‘主播’就和英雄联盟主播赏金术士有责很大关系了。 外甥是赏金双排的一位选手、扮演着搞笑、逗乐的角色。‘无限’则是“无限火力”，一个特定模式，颇受玩家喜爱。主播可能是赏金，也有可能说别的主播。 关键短语： 对面不会 垃圾主播 不出 没带 不大 赏金玩 对面德玛 外甥说 大不 外甥大 摘要： 7337 0.0006968086282134394 真的有护眼模式666 3059 0.0006968086282134393 护眼模式为什么这么绿 10503 0.00047342729603724247 找儿子，爱好护眼 从摘要中看到三条弹幕中，都含有“护眼”二字，这是为什么呢？ lol护眼一词，其实主要来源于英雄联盟的直播平台，随着叫的人多了，这个词便火热了起来。起初是有人带节奏，说打护眼斗鱼可以进入护眼模式。一般在直播lol的主播使用的英雄死掉后，界面会呈现暗灰色的，亮度降低有利于防护眼睛，从而就有了lol护眼，当然意思就是嘲讽主播很菜的意思。 三、总结：由于自己所收集的数据过少、而且仅保存了一位主播的弹幕，造成结果不具有通用性，可以通过对各大直播平台的热门主播弹幕的爬取，获得观众的心理变化和网络风气。 以及主播有没有过气一说~ github：https://github.com/zhangslob/DanmuFenxi","tags":[{"name":"直播","slug":"直播","permalink":"https://zhangslob.github.io/tags/直播/"},{"name":"文本分析","slug":"文本分析","permalink":"https://zhangslob.github.io/tags/文本分析/"}]},{"title":"如何优雅的“轮带逛”初级篇——获取单张图片","date":"2017-03-20T12:35:00.000Z","path":"2017/03/20/如何优雅的“轮带逛”初级篇——获取单张图片/","text":"这是崔斯特的第六篇原创文章 轮子哥护体 首先上收藏夹 https://www.zhihu.com/collection/78172986?page=1 由@vega13创建，内容挺多的。例如， 等等，看的老夫脸都红了 写了一个简单爬取图片的程序。记录下过程。手动 @轮子哥 1、分析网页收藏夹只收藏了问题的一个答案，初步想法是获取当前页面的图片 因为上一次原因，直接去网页源代码 &lt;img src=&quot;https://pic4.zhimg.com/de5ecb16bcb912e99a83f647eb96c5bb_200x112.jpg&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image inline-img zh-lightbox-thumb&quot; data-original=&quot;https://pic4.zhimg.com/de5ecb16bcb912e99a83f647eb96c5bb_r.jpg&quot;&gt; &lt;img data-rawwidth=&quot;1280&quot; data-rawheight=&quot;1836&quot; src=&quot;https://pic2.zhimg.com/v2-61ba67d910104f99acdb805a3568ab05_200x112.jpg&quot; class=&quot;origin_image inline-img zh-lightbox-thumb&quot; data-original=&quot;https://pic2.zhimg.com/v2-61ba67d910104f99acdb805a3568ab05_r.jpg&quot;&gt; 在&lt;img&gt;标签下，src和data-original都含有图片链接，经验证data-original是大图，那就把每个问题的图片链接找到了，接下来就很简单了。 2、代码就18行的代码。简单吧~ import requests,urllib from lxml import etree def get_img(url): headers = {&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;} r= requests.get(url,headers=headers).text s = etree.HTML(r) #print(r) link = s.xpath(&apos;//img/@data-original&apos;) for i in link: print(i) name = i.split(&apos;/&apos;)[-1]#图片名称 urllib.request.urlretrieve(i,name) if __name__ == &apos;__main__&apos;: for i in range(1,43): url = &apos;https://www.zhihu.com/collection/78172986?page=&apos; + str(i) get_img(url) 但是这样存在一个问题 link = s.xpath(&apos;//img/@data-original&apos;) 这里的link只有每个回答的第一张图片，更多的图片藏在文本中，除了正则不知道还有没有更好的办法 只有200多张图片。结尾有百度云 下载了几分钟出现错误，有一张图片下载不了，知友们有什么好办法吗？ 三、“轮带逛”高级篇既然有初级篇，肯定还有高级篇。 其实这个收藏夹中每一个问题下面都含有很多回答，收藏夹只是选取其中一个，也就是被轮子哥点赞的那个，那么还有那些没有被点赞的呢？ 下一期讲一讲怎么获取所有图片链接。 放一张图片，卡死我程序的 —————————————最后的小广告—————————————– 有朋友竟然叫我去作一期直播，讲一讲Python。 打算根据自己的经历分享一些经验，主要是关于Python入门的，想听听可以私信我。 时间是周二晚9点~ 百度云下载 链接：http://pan.baidu.com/s/1dFOPbUx 密码：abrl","tags":[{"name":"知乎爬虫","slug":"知乎爬虫","permalink":"https://zhangslob.github.io/tags/知乎爬虫/"},{"name":"轮带逛","slug":"轮带逛","permalink":"https://zhangslob.github.io/tags/轮带逛/"}]},{"title":"Python爬虫实战——免费图片 - Pixabay","date":"2017-03-19T09:24:58.000Z","path":"2017/03/19/Python爬虫实战——免费图片-Pixabay/","text":"这是崔斯特的第五篇原创文章 Pixabay，一个挺不错的高清无码图片网站，可以免费下载。 https://pixabay.com/ 一些介绍 超过 900000 高质量照片、 插图和矢量图形。可免费用于商业用途。没有所需的归属。 Pixabay是一家高质量图片分享网站。最初，该网站由Hans Braxmeier和Simon Steinberger在德国发展起来。2013年2月，网站拥有由影师和其社区的插画家提供的大约7万张免费的照片和矢量图形。该公司于2010年12月在德国乌尔姆成立。 2012年3月，Pixabay开始从一个私人图像搜集网站转变成一个互动的网上社区，该网站支持20种语言。同年5月，网站推出公共应用程序编程接口，从而使第三方用户和网站开发人员搜索其图像数据库。网站还与Flickr，YouTube和维基共享资源。 Pixabay用户无需注册就可以获得免费版权的高质量图像。根据知识共享契约CC0相关的肖像权，用户在该网站通过上传图片就默认放弃图片版权，从而使图片广泛流通。网站允许任何人使用，修改图片 - 即便是在商业应用 - 不要求许可并且未认可。 Pixabay为了确保高品质图片标准，用户上传的所有图片将由网站工作人员手动审批。大约27％的用户会说英语，20％的用户会说西班牙语，11％的用户会说葡萄牙语，7％的用户会说德语和5％的用户会说法语。其用户主要是博客、图形设计师、作家、记者和广告商。 今天的目标就是爬取小编精选的图片 https://pixabay.com/zh/editors_choice/?media_type=photo&amp;pagi=1 一、分析我们需要写3个函数 一个Download(url)，用来下载图片 一个用来获取小编精选一共有的165页FullUrl() 最后用来调用main() 下面开始一个个写吧~ https://pixabay.com/zh/editors_choice/?media_type=photo&amp;pagi=1 打开网页，F12，查看图片链接所在的标签 可以看到图片链接都在&lt;img&gt;标签下，但是我自己发现前几张和后几张的属性是不一样的，提取出&lt;img&gt;中“src”就可以了，使用的是xpath import requests from lxml import etree header = {&apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;} url = &apos;https://pixabay.com/zh/editors_choice/&apos; r = requests.get(url,headers=header).text s = etree.HTML(r) print(s.xpath(&apos;//img/@src&apos;)) 结果是 前面都是正确的图片链接，可是后面出现了’/static/img/blank.gif’，这个是什么鬼，查看网页源代码，搜索 可以发现确实有这一段字符串，我自己在这一点上花了很多时间。感谢@李宏杰的帮助，https://www.zhihu.com/question/57188290 浏览器中的代码是JavaScript修改过的, 你直接用requests请求然后打印出来看就会发现 &lt;div class=&quot;item&quot; data-w=&quot;640&quot; data-h=&quot;426&quot;&gt; &lt;a href=&quot;/zh/%E8%9B%8B%E7%B3%95-%E4%B8%80%E5%9D%97%E8%9B%8B%E7%B3%95-%E9%A3%9F%E8%B0%B1-%E4%B8%80%E7%89%87-%E7%B3%96%E6%9E%9C-%E6%8F%92%E5%9B%BE-%E7%83%98%E7%83%A4-%E7%94%9C%E7%82%B9-%E9%A3%9F%E5%93%81-1971556/&quot;&gt; &lt;img src=&quot;/static/img/blank.gif&quot; data-lazy-srcset=&quot;https://cdn.pixabay.com/photo/2017/01/11/11/33/cake-1971556__340.jpg 1x, https://cdn.pixabay.com/photo/2017/01/11/11/33/cake-1971556__480.jpg 2x&quot; data-lazy=&quot;https://cdn.pixabay.com/photo/2017/01/11/11/33/cake-1971556__340.jpg&quot; alt=&quot;&quot;&gt; &lt;/a&gt; &lt;div&gt; requests返回的数据中可以看到，“data-lazy”总含有我们需要的数据，修改代码 发现现在返回的数据是我们需要的，打开一张图片查看 下面的图片要清晰很多，我们只需要把__340换成_960_720即可 小编精选一共有165页，我们需要获取下一页URL https://pixabay.com/zh/editors_choice/?media_type=photo&amp;pagi=2 https://pixabay.com/zh/editors_choice/?media_type=photo&amp;pagi=3 。。。 规律很简单 full_link = [] for i in range(1,165): #print(i) full_link.append( &apos;https://pixabay.com/zh/editors_choice/?media_type=photo&amp;pagi=&apos;+ str(i)) 到现在，准备工作做好了，思路可能不是很清楚，请谅解~ 二、代码import requests from lxml import etree import time import urllib def Download(url): header = { &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;} r = s.get(url, headers=header).text s = etree.HTML(r) r = s.xpath(&apos;//img/@data-lazy&apos;) for i in r: imglist = i.replace(&apos;__340&apos;, &apos;_960_720&apos;) name = imglist.split(&apos;/&apos;)[-1]#图片名称 urllib.request.urlretrieve(imglist,name) time.sleep(1) def FullUrl(): full_link = [] for i in range(2,165): #print(i) full_link.append( &apos;https://pixabay.com/zh/editors_choice/?media_type=photo&amp;pagi=&apos;+ str(i)) #print(full) return full_link if __name__ == &apos;__main__&apos;: urls = FullUrl() for url in urls: Download(url) 爬取图片的工作就完成了，粗略的计算6600张，每一张下载需要5秒钟，一分钟60秒、一小时60分钟，天呐，需要9个小时才能爬取全部的图片。想一想还是算了吧，整站爬取还是要使用Scrapy+mongodb。 &gt;&gt;&gt; 165*40 6600 &gt;&gt;&gt; from __future__ import division &gt;&gt;&gt; 6600*5/60/60 9.166666666666666 下载了700多张，108M，也算是留着看看吧。 一会上传到Github上 三、结语昨天学习了崔庆才老师的爬虫，感觉真的学习到了好多，对Python爬虫提高很有帮助，还有，原来他就是静觅，刚开始学习爬虫就在看他的博客，没想到他现在又在出爬虫教程，打算跟着学习。 分享内容： 1. 分析知乎Ajax请求及爬取逻辑 2. 用Scrapy实现递归爬取 3. 爬取结果存储到MongoDB 废话不多说，自己看看就知道了。 静觅丨崔庆才的个人博客http://cuiqingcai.com/ 微课录播 | 03月17日 爬取知乎所有用户详细信息https://edu.hellobi.com/course/163 最后的小广告 有朋友竟然叫我去作一期直播，讲一讲Python。 打算根据自己的经历分享一些经验，主要是关于Python入门的，想听听可以私信我。 时间是周二晚9点~ Hello World！ Try to be a Pythoner！","tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://zhangslob.github.io/tags/爬虫/"},{"name":"图片下载","slug":"图片下载","permalink":"https://zhangslob.github.io/tags/图片下载/"}]},{"title":"Python练习第九题，爬取贴吧图片","date":"2017-03-14T11:56:07.000Z","path":"2017/03/14/Python练习第九题，爬取贴吧图片/","text":"这是崔斯特的第四篇原创文章 一、问题：用 Python爬取妹子图片 :) http://tieba.baidu.com/p/2166231880 二、分析贴吧网页源码打开网页http://tieba.baidu.com/p/2166231880，F12 发现图片链接都在&lt;img&gt;标签中 &lt;cc&gt; &lt;div...&gt; &lt;img...&gt; &lt;img...&gt; 测试发现，src中的链接就是图片链接。那么就很简单，只需要把&lt;img&gt;中的src的链接拿出来即可。 三、写代码环境：Python3，Pycharm 使用requests和xpath，最近才学了xpath，发现超级好用，比bs4简洁，有兴趣看看这个https://zhuanlan.zhihu.com/p/25572729 import requests from lxml import etree url = &apos;http://tieba.baidu.com/p/2166231880&apos; header = {&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&apos;} r = requests.get(url,headers=header).content s = etree.HTML(r) print(s.xpath(&apos;//div/img/@src&apos;)) 发现链接都已经拿到手，下一步就是下载了~ 下载图片的语句： import urllib.request path = &apos;......&apos; #下载链接 jpg_link ＝ &apos;......&apos; #图片链接 request.urlretrieve(jpg_link, path) 加在一起，大功告成。 四、总结经测试，贴吧里面其他网页如：http://tieba.baidu.com/p/1165861759 本代码都可以下载，顺便说一说问题。 1、图片名称使用图片链接中的名称，包含大量数字和字母，可以优化。 2、可以看到，下载文件中包含了一个表情，查看那是用户所发，说明筛选出了问题。 3、帖子数量多，翻页过后，需要在代码中加入获取下一页链接。 除此之外，还有什么问题呢？ 源码请见：https://github.com/zhangslob/TiebaImg","tags":[{"name":"福利","slug":"福利","permalink":"https://zhangslob.github.io/tags/福利/"},{"name":"美女图片","slug":"美女图片","permalink":"https://zhangslob.github.io/tags/美女图片/"}]},{"title":"Python练习第七题，我要倒过来看","date":"2017-03-06T10:47:46.000Z","path":"2017/03/06/Python练习第七题，我要倒过来看/","text":"这是崔斯特的第三篇原创文章 一、ChallengeUsing the Python language, have the function FirstReverse(str) take the str parameter being passed and return the string in reversed（颠倒的） order. For example: if the input string is “Hello World and Coders” then your program should return the string sredoC dna dlroW olleH.题目意思是，给定字符串，返回原来的倒序。例如给出的是“Hello World and Coders”，返回“sredoC dna dlroW olleH.” Sample Test Cases Input:”coderbyte” Output:”etybredoc” Input:”I Love Code” Output:”edoC evoL I” Hint Think of how you can loop through a string or array of characters backwards to produce a new string. def FirstReverse(str): # code goes here return str # keep this function call here print FirstReverse(raw_input()) 二、解法:切片环境：Python3.5 A simple way to reverse a string would be to create a new string and fill it with the characters from the original string, but backwards. To do this, we need to loop through the original string starting from the end, and every iteration of the loop we move to the previous character in the string. Here is an example: def FirstReverse(str): return str[::-1] print (FirstReverse(input())) 非常简洁str[::-1]就可以完成目标。 三、切片详解1、取字符串中第几个字符 &gt;&gt;&gt; &apos;hello&apos;[0]#表示输出字符串中第一个字符 &apos;h&apos; &gt;&gt;&gt; &apos;hello&apos;[-1]#表示输出字符串中最后一个字符 &apos;o&apos; 2、字符串分割 &gt;&gt;&gt; &apos;hello&apos;[1:3] &apos;el&apos; 第一个参数表示原来字符串中的下表第二个参数表示分割后剩下的字符串的第一个字符 在 原来字符串中的下标 注意，Python从0开始计数 3、几种特殊情况 &gt;&gt;&gt; &apos;hello&apos;[:3]#从第一个字符开始截取，直到最后 &apos;hel&apos; &gt;&gt;&gt; &apos;hello&apos;[0:]#从第一个字符开始截取，截取到最后 &apos;hello&apos; &gt;&gt;&gt; &apos;hello&apos;[:] &apos;hello&apos; 4、步长截取 &gt;&gt;&gt; &apos;abcde&apos;[::2]#表示从第一个字符开始截取，间隔2个字符取一个。 &apos;ace&apos; &gt;&gt;&gt; &apos;abcde&apos;[::-2] &apos;eca&apos; &gt;&gt;&gt; &apos;abcde&apos;[::-1] &apos;edcba&apos; 推荐阅读： 官方文档https://docs.python.org/3/tutorial/introduction.html#strings 廖雪峰的教程 http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431756919644a792ee4ead724ef7afab3f7f771b04f5000 更多解法： def FirstReverse(str): # reversed(str) turns the string into an iterator object (similar to an array) # and reverses the order of the characters # then we join it with an empty string producing a final string for us return &apos;&apos;.join(reversed(str)) print(FirstReverse(input())) 使用了什么语法？评论中见。","tags":[{"name":"Python语法","slug":"Python语法","permalink":"https://zhangslob.github.io/tags/Python语法/"},{"name":"切片介绍","slug":"切片介绍","permalink":"https://zhangslob.github.io/tags/切片介绍/"}]},{"title":"教你免费搭建个人博客，Hexo&Github","date":"2017-02-28T12:01:50.000Z","path":"2017/02/28/教你免费搭建个人博客，Hexo-Github/","text":"这是崔斯特的第二篇原创文章 说在前面： 为什么自己搭建博客，知乎不行吗？可以看看刘未鹏 | Mind Hacks，前些天发布了某篇文章应该是被人举报了，结果知乎就删了。有自己的博客自由，自在。更多请看为什么要自建博客？https://www.zhihu.com/question/19916345 说在前面： 为什么自己搭建博客，知乎不行吗？可以看看刘未鹏 | Mind Hacks，前些天发布了某篇文章应该是被人举报了，结果知乎就删了。有自己的博客自由，自在。更多请看为什么要自建博客？https://www.zhihu.com/question/19916345 我用了多久才完成博客的搭建？不瞒您说，我花了有3天时间。对着别人的“5分钟 搭建免费个人博客”花了3天才完成，中间遇到了无数困难。查看很多资料，所以当你遇到困难，别放弃，仔细看文档或资料。 为了发布这篇教程，重新注册了Github，崔斯特的博客https://zhangslob.github.io/这个是我自己的博客，崔斯特测试所用博客https://zhihuya.github.io/这个是我一边写这篇教程一边搭建的。所以如果你也和我一样，喜欢自由，喜欢捣腾，那就来吧。 系统：windows 7 64位，编辑器：sublime text3，控制台：cmder搭建博客使用hexo+Github 什么是 Hexo？https://hexo.io/zh-cn/docs/ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 一、配置Github首先注册、登录 https://github.com/ 记住自己的Username（很重要） 然后右上角选择 Create a new repository https://github.com/new Repository name （填自己的名字） yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了) 例如，我的域名是github.com/zhihuya，就填入zhihuya.github.io。成功后出现下面的画面 二、环境安装（node、git）1、安装 Node.js https://nodejs.org/en/ 2、安装 Git https://github.com/waylau/git-for-win Git教程 https://github.com/waylau/git-for-win廖雪峰老师的教程，非常好。 3、安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，名称和邮箱是Github上的 4、安装 Hexo。所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 $ npm install -g hexo-cli （使用的cmder，超级好用~~。等待时间可能有点长） 好了到这一步我们环境全部安装好了。 三、设置在电脑F盘（自己随意）目录下新建文件夹 test，进入test，按住Shift键点击鼠标右键 因为我有安装Cmder，没有安装的点击“在此处打开命令窗口”，输入 hexo init blog 稍微等待下，速度有点慢。成功提示 INFO Start blogging with Hexo! 因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令 $ hexo generate # 启动本地服务器 $ hexo server # 在浏览器输入 http://localhost:4000/就可以看见网页和模板了 INFO Start processing INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 访问http://localhost:4000/，便可以看到网站初步的模样，不要激动，我们还要把网页发布到Github上去。 重新打开CMD，输入： ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot; 一路Enter过来就好，得到信息： Your public key has been saved in /c/Users/user/.ssh/id_rsa.pub. 找到该文件，打开（sublime text），Ctrl + a复制里面的所有内容，然后进入Sign in to GitHub：https://github.com/settings/ssh New SSH key ——Title：blog —— Key：输入刚才复制的—— Add SSH key 四、配置博客在blog目录下，用sublime打开_config.yml文件，修改参数信息 特别提醒，在每个参数的：后都要加一个空格 修改网站相关信息 title: 崔斯特测试所用博客 subtitle: 副标题 description: 网页描述 author: 崔斯特 language: zh-CN timezone: Asia/Shanghai 配置部署（我的是zhihuya，修改成自己的） deploy: type: git repo: https://github.com/zhihuya/zhihuya.github.io.git branch: master 五、发表文章在CMD中输入 $ hexo new &quot;崔斯特测试文章&quot; INFO Created: F:\\test\\blog\\source\\_posts\\崔斯特测试文章.md 找到该文章，打开，使用Markdown语法，该语法介绍可以查看https://zhangslob.github.io/2017/02/26/%E5%88%A9%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E7%9A%84%E5%8D%9A%E5%AE%A2/ --- title: 崔斯特测试文章 date: 2017-02-28 13:03:44 tags: --- 这是一篇测试文章，欢迎关注作者博客[1]: https://zhangslob.github.io/ 保存，然后执行下列步骤： F:\\test\\blog $ hexo clean INFO Deleted database. INFO Deleted public folder. F:\\test\\blog $ hexo generate INFO Start processing INFO Files loaded in 1.48 s #省略 INFO 29 files generated in 4.27 s F:\\test\\blog $ hexo server INFO Start processing INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 这个时候，打开http://localhost:4000/，发现刚才的文章已经成功了 最后一步，发布到网上，执行： F:\\test\\blog $ hexo deploy INFO Deploying: git INFO Clearing .deploy_git folder... INFO Copying files from public folder... #省略 其中会跳出Github登录，直接登录，如果没有问题输入zhihuya（换成你的）.github.io/ 崔斯特测试所用博客https://zhihuya.github.io/ 然后就可以看到已经发布了 六、总结发布文章的步骤： 1、hexo new 创建文章 2、Markdown语法编辑文章 3、部署（所有打开CMD都是在blog目录下） hexo clean #清除缓存 网页正常情况下可以忽略此条命令 hexo generate #生成 hexo server #启动服务预览，非必要，可本地浏览网页 hexo deploy #部署发布 简写Tips： hexo n “我的博客” == hexo new “我的博客” #新建文章 hexo p == hexo publish hexo g == hexo generate#生成 hexo s == hexo server #启动服务预览 hexo d == hexo deploy#部署 如果在执行 hexo deploy 后,出现 error deployer not found:github 的错误，执行： npm install hexo-deployer-git --save 出错是正常的，出错了自己先百度或google，实在不知道的可以询问我。 托管的话不仅有github可以用，还有个国内的https://coding.net/可选 到这里已经完成了博客的搭建，但是还有很多需要设置和调整的。这是我的博客，也许你会发现，我和刚才搭建的不一样，因为我修改了博客主题，简洁、优美。 主题介绍https://github.com/litten/hexo-theme-yilia 欢迎大家关注，定会有更多精彩 知乎https://www.zhihu.com/people/cuishite 博客https://zhangslob.github.io/","tags":[{"name":"个人博客","slug":"个人博客","permalink":"https://zhangslob.github.io/tags/个人博客/"},{"name":"Hexo&Github","slug":"Hexo-Github","permalink":"https://zhangslob.github.io/tags/Hexo-Github/"}]},{"title":"利用HEXO搭建的博客及Markdown语法介绍","date":"2017-02-26T09:20:57.000Z","path":"2017/02/26/利用HEXO搭建的博客/","text":"这是崔斯特的第一篇原创文章 Markdown的一些语法 花了不少时间。终于把自己的第一个博客搭建成功了。但是遇到新问题，发表文章需要使用Markdown语法，下面就来说说。 Markdown的文档介绍http://www.appinn.com/markdown/看看简单介绍就可以了，以后有需求再去学习。 1、标题和引用。Markdown 支持两种标题的语法，Setext 和 atx 形式。Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），Atx 形式在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶。 区块引用则使用 email 形式的 ‘&gt;’ 角括号。 如你所见，左边是编辑区，右边可以直接看到结果。编辑器是MarkdownPad，下载链接是http://markdownpad.com/download.html 2、修辞和强调。 3、链接和图片。（如果你有下载MarkdownPad这个编辑器，会更加方便哦） 4、加入代码,使用单引号。 这些应该可以帮助我完成一般书写，好的呢，第一篇文章就完成了。 欢迎评论。。 人生苦短，我学Python (๑• . •๑) 2017/2/27 19:11:11","tags":[{"name":"黑魔法","slug":"黑魔法","permalink":"https://zhangslob.github.io/tags/黑魔法/"},{"name":"个人博客","slug":"个人博客","permalink":"https://zhangslob.github.io/tags/个人博客/"},{"name":"Markdown语法","slug":"Markdown语法","permalink":"https://zhangslob.github.io/tags/Markdown语法/"}]}]